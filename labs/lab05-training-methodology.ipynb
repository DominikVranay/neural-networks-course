{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cvičenie 5: Metodológia trénovania a vyhodnotenia neurónových sietí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cieľom tohto cvičenia je oboznámiť vás so základnými krokmi, ktoré by ste mali vykonať pri trénovaní neurónových sietí. Tieto kroky platia všeobecne pre všetky metódy umelej inteligencie, ale niektoré úlohy sú špecifické pre neurónové siete. Metodológiu vysvetlíme na klasifikačnej úlohe, na definíciu a trénovanie neurónovej siete budeme používať knižnicu [Keras](https://keras.io). Ak Keras alebo tensorflow ešte nemáte nainštalovaný, nainštalujte si ho podľa [tohto návodu](https://github.com/ianmagyar/neural-networks-course/blob/master/labs/lab00-getting-started.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postup vývoja neurónových sietí vieme rozdeliť do nasledujúcich krokov:\n",
    "1. predspracovanie údajov\n",
    "2. návrh siete\n",
    "3. trénovanie siete\n",
    "4. vyhodnotenie siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predspracovanie údajov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predspracovanie údajov je prvý krok, ktorý v sebe zahŕňa hneď niekoľko úloh:\n",
    "* načítanie datasetu\n",
    "* výber príznakov\n",
    "* normalizácia hodnôt\n",
    "* vektorizácia vstupov a výstupov\n",
    "* rozdelenie datasetu na trénovaciu, testovaciu a validačnú množinu.\n",
    "\n",
    "Postup pri predspracovaní údajov ukážeme na Iris datasete. Stiahnite si [dataset s implementáciou neurónovej siete](sources/lab05/lab5.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Načítanie datasetu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na načítanie datasetu existujú rôzne knižnice pre Python, jedna populárna z nich je knižnica `pandas`. Knižnica dokáže načítať rôzne formátované dáta, napríklad formáty csv, html, json, hdf5 a SQL. Náš dataset vieme načítať priamo zo súboru csv nasledovným spôsobom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('iris.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načítaný dataset má typ DataFrame. K ľubovoľným stĺpcom sa dostaneme zadaním názvu stĺpca ako index datasetu. Ak chceme zobraziť viac stĺpcov, index musí byť zoznam s názvami týchto stĺpcov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only column SepalLengthCm\n",
    "print(dataset['SepalLengthCm'])\n",
    "\n",
    "# select columns SepalLengthCm and SepalWidthCm\n",
    "print(dataset[['SepalLengthCm', 'SepalWidthCm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatívne vieme zobraziť stĺpce ako keby boli parametrom objektu dataset, alebo vieme použiť aj poradové číslo stĺpca (znak `:` pred čiarkou vyjadruje všetky riadky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.SepalLengthCm)\n",
    "print(dataset.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K riadkom pristupujeme cez číselné indexy, pričom dokopy ich môžeme mať až tri. Prvé číslo vyjadruje poradové číslo prvého riadku, druhé číslo poradové číslo posledného riadku (vľavo uzavretý interval, podľa [pravidiel indexovania v Pythone](https://www.digitalocean.com/community/tutorials/how-to-index-and-slice-strings-in-python-3)), a tretie číslo step. Takto vieme napríklad vypísať každý druhý riadok z intervalu 1-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0:10:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatívne môžete použiť aj `loc` funkciu DataFrame-ov (podľa indexu atribútu; druhý index vyjadruje otvorený interval), alebo `iloc` funkciu (podľa poradia; druhý index vyjadruje otvorený interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.loc[0:9:2])\n",
    "print(dataset.iloc[0:9:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexovanie riadkov a stĺpcov viete aj kombinovať, na poradí nezáleží:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[:10:2]['SepalLengthCm'])\n",
    "print(dataset['SepalLengthCm'][:10:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z datasetu viete vybrať iba niektoré riadky aj na základe hodnoty niektorého atribútu použitím `lambda` funkcie. Napríklad, pre všetky riadky, kde hodnota SepalLengthCm je viac ako 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.loc[lambda df:df.SepalLengthCm > 5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Všetky tieto podmnožiny majú typ `DataFrame`. Ak chcete hodnoty použiť ako zoznam, resp. zoznam zoznamov, musíte pridať `values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['SepalLengthCm'][:10:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Výber príznakov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pred výberom príznakov potrebujeme získať intuitívne pochopenie datasetu a vzťahov medzi jednotlivými atribútmi a výsledkom klasifikácie. V tomto nám pomôže knižnica `Seaborn`, ktorá slúži na vizualizáciu údajov a využíva knižnicu `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set plot style\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# create plots over all dataset; for subset use iloc indexing\n",
    "sns.pairplot(dataset, hue=\"Species\")\n",
    "\n",
    "# display plots using matplotlib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uvedený kód namapuje záznamy z datasetu v každom možnom príznakovom priestore vo dvojiciach príznakov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Vizualizácia datasetu](sources/lab05/5.1-dataset-visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z grafov vidíme, že ani jedna kombinácia nám nedá lineárne separovateľný dataset, budeme teda používať všetky príznaky, ktoré vyberieme pomocou knižnice `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into input (X - select the first four columns) and output (y - select last column)\n",
    "X = dataset.iloc[:, :4].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Normalizácia hodnôt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizácia hodnôt sa používa najmä pre zložitejšie datasety a urýchli proces trénovania neurónových sietí, ktoré lepšie pracujú s dátami z istého intervalu. Počas normalizácie sa číselné hodnoty namapujú zvyčajne na interval 0 až 1.\n",
    "\n",
    "Neskôr boli vyvinuté špeciálne vrstvy neurónovej siete práve pre normalizáciu, dnes sa skôr používa takto automatizovaný spôsob normalizácie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Vektorizácia vstupov a výstupov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kým neurónové siete dokážu spracovať iba číselné hodnoty, skoro všetky datasety obsahujú aj nečíselné údaje (reťazce, kategórie, booleovské hodnoty, atď.). Preto je potrebné, aby sme tieto hodnoty premenili na vektorovú reprezentáciu. Pri vektorizácii upravíme výstupy na formu *n* čísel, kde *n* je počet tried pri klasifikácii. Každý vektor bude obsahovať práve jednu 1 a ostatné hodnoty budú 0, tieto čísla vyjadrujú mieru príslušnosti k jednotlivým triedam.\n",
    "\n",
    "V našom datasete potrebujeme upraviť očakávaný výstup, ktorý zatiaľ má formu reťazca. Pri vektorizácii vieme využiť `LabelEncoder` z knižnice `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "# transform string labels into number values 0, 1, 2\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "# transform number values into vector representation\n",
    "Y = pd.get_dummies(y1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Poznámka:** v niektorých prípadoch dokážete reťazce nahradiť jednoduchými číslami, takýto spôsob ale predpokladá, že čísla, ktoré sú blízko sebe vyjadrujú koncepty, ktoré sú veľmi podobné. Napríklad, ak máme stĺpec s hodnotami *low*, *middle*, *high*, tieto hodnoty vieme nahradiť číslami 1, 2 a 3. Rovnaký spôsob ale nemôžeme použiť s hodnotami ako napríklad značky auta: *Škoda* (1), *Audi* (2), *Lada* (3), pretože neurónová sieť by predpokladala, že Lada (3) je viac podobná Audi (2) ako Škodovke (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Rozdelenie datasetu na trénovaciu, testovaciu a validačnú množinu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ďalšou úlohou je rozdelenie množiny na trénovaciu a testovaciu. Na to použijeme ďalšiu funkciu z knižnice `scikit-learn`, a to `train_test_split` ([dokumentácia](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)), ktorá zachová poradie vstupov a výstupov a má tri dôležité parametre:\n",
    "1. zoznam vstupov\n",
    "2. zoznam výstupov\n",
    "3. test_size - veľkosť testovacej množiny medzi 0 a 1 (môžete použiť aj train_size)\n",
    "\n",
    "Pre opakovateľnosť trénovania je odporúčané používať random seed zadaním parametra `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validačná množina sa pri jednoduchých datasetoch až tak často nepoužíva, slúži ako testovacia množina počas fázy trénovania a môže byť použitá ako podmienka pre ukončenie trénovania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Návrh siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na definíciu siete použijeme knižnicu Keras, v ktorej potrebujem tri veci na vytvorenie jednoduchej siete:\n",
    "\n",
    "1. model - v tomto kroku použijeme jednoduchý feed-forward sekvenčný model ([dokumentácia](https://keras.io/models/sequential/))\n",
    "2. vrstvy - použijeme iba plne prepojené dense vrstvy ([dokumentácia](https://keras.io/layers/core/#dense))\n",
    "3. optimalizátor - algoritmus, ktorý nám zadefinuje spôsob trénovania siete; my použijeme optimalizátor Adam ([dokumentácia](https://keras.io/optimizers/#adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V Kerase musíme najprv vytvoriť model a doňho pridať vrstvy. Pri definícii vrstiev potrebujeme zadať počet neurónov vo vrstve a aktivačnú funkciu. Špecifická je prvá vrstva v sieti, keďže pre ňu potrebujeme zadefinovať aj počet vstupných neurónov. Počet neurónov v poslednej vrstve má zodpovedať formátu výstupu siete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10,input_shape=(4,),activation='tanh'))\n",
    "# TODO: add dense layer with 8 neurons and tanh activation function\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "# TODO: add dense layer with 6 neurons and tanh activation function\n",
    "model.add(Dense(6, activation='tanh'))\n",
    "# TODO: add dense layer with 3 neurons and softmax activation function\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pred trénovaním siete ešte potrebujeme zadefinovať spôsob trénovania cez optimalizátor. Urobíme tak zavolaním funkcie `compile` ([dokumentácia](https://keras.io/models/sequential/#compile)) s nasledujúcimi parametrami:\n",
    "* optimizer (optimalizátor)\n",
    "* loss function (chybová funkcia)\n",
    "* metrics (metriky) - nie je povinné, slúži iba na vyhodnotenie neurónovej siete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.04), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trénovanie siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ak sme spokojní so sieťou, môžeme ju začať trénovať pomocou fukcie `fit` ([dokumentácia](https://keras.io/models/sequential/#fit)). V tomto kroku použijeme iba niektoré parametre funkcie:\n",
    "* vstupy - pole vstupov z trénovacej množiny\n",
    "* výstupy - pole so správnymi výstupmi z trénovacej množiny\n",
    "* počet epoch - epocha je jedna iterácia nad celou trénovacou množinou\n",
    "\n",
    "Ďalšie často používané parametre:\n",
    "* batch_size - batch slúži na presnejšiu gradient aktualizáciu\n",
    "* verbose - definuje, či chceme zobraziť progress počas trénovania; môže mať hodnoty 0 (žiaden výstup), 1 (medzivýsledok po každom batchi) a 2 (medzivýsledok po epoche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vyhodnotenie siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnotenie siete pozostáva z dvoch základných úloh: testovanie a vyhodnotenie. Pre testovanie musíme získať výstupy ku vstupným hodnotám z trénovacej množiny pomocou metódy `predict` ([dokumentácia](https://keras.io/models/sequential/#predict)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ďalej porovnáme ozajstné výstupy s očakávanými. Keďže výstup má vektorovú reprezentáciu, potrebujeme zistiť pozíciu kde sa nachádza najväčšia hodnota vo vektore. V tomto nám pomôže knižnica `numpy`, ktorú sme zatiaľ nepoužili explicitne, ale podporuje všetky už použité knižnice. Jedná sa o efektívne a optimalizované riešenie práce s poľami.\n",
    "\n",
    "Pre vyhodnotenie našej siete použijeme konfúznu maticu. Konfúzna matica je tabuľková reprezentácia, kde v riadkoch máme očakávané triedy a v stĺpcoch vypočítané (predikované). V bunkách tabuľky sú uložené počty príkladov klasifikované v danej kombinácii očakávanej a predikovanej triedy. Ideálny klasifikátor bude mať všetky hodnoty po hlavnej diagonále (ďalšie informácie nájdete na [wikipédii](https://en.wikipedia.org/wiki/Confusion_matrix))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z konfúznej matici potom vieme vypočítať ďalšie metriky, ako presnosť (accuracy), návratnosť (recall) a precizita (precision):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presnosť popisuje samotný klasifikátor a vypočíta sa nasledovne:\n",
    "\n",
    "$ACC = \\frac{TP + TN}{P + N}$\n",
    "\n",
    "kde TP + TN je suma správne klasifikovaných príkladov (na hlavnej diagonále) a P + N je počet všetkých príkladov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Návratnosť a precizita popisujú klasifikátor pre danú triedu, vypočítajú sa nasledovne:\n",
    "\n",
    "$REC = \\frac{TP}{P}$\n",
    "\n",
    "$PREC = \\frac{TP}{TP + FP}$\n",
    "\n",
    "kde TP je počet správne klasifikovaných príkladov z danej triedy, P je počet príkadov z danej triedy v testovacej množine a FP je počet príkladov z testovacej množiny nesprávne klasifikovaných do tejto triedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metóda `classification_report` vypočíta ešte hodnotu F1, ktorá je harmonický priemer návratnosti a precizity:\n",
    "\n",
    "$F1 = 2 \\cdot \\frac{REC \\cdot PREC}{REC + PREC}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
