{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Getting to know TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na tomto cvičení si zopakujeme základné poznatky ktoré ste získali na predmete Neurónové siete. Vysvetlíme si, ako funguje perceptrón, čo sú aktivačné funkcie a načo slúžia, ako sa trénujú neurónové siete. Následne sa oboznámime so základnými funkciami a prvkami softvérového rámca TensorFlow.\n",
    "\n",
    "**Zdroje**\n",
    "\n",
    "[Introduction to Deep Learning 1. prednáška](http://introtodeeplearning.com/materials/2019_6S191_L1.pdf)\n",
    "\n",
    "[Dokumentácia TensorFlow](https://www.tensorflow.org/api_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importovanie TensorFlow\n",
    "\n",
    "Na to, aby sme vedeli zadefinovať naše prvé neurónové siete, je potrebné mať nainštalovaný a načítaný softvérový rámec TensorFlow. Návod na inštaláciu nájdete v [Lab 0](https://github.com/ianmagyar/dl-course/blob/master/labs/lab0-getting-ready.md).\n",
    "\n",
    "Ak už máte nainštalovaný TensorFlow, neostáva Vám nič iné, ako ho načítať:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri Eager vykonávaní sa operácie vykonajú okamžite pri volaní z Pythonu, čo nám umožňuje rýchle debugovanie a práve preto vám ho odporúčame používať pri vytvoraní vašich riešení."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Výpočty v TensorFlowe\n",
    "\n",
    "Pred tým než vytvoríme naše prvé neurónové siete v TensorFlowe, oboznámime sa so základnými výpočtami. Názov TensorFlow popisuje spôsob vykonávania výpočtov v tomto softvérovom rámci. Tensory sú vlastne údaje (hodnoty alebo viacdimenzionálne polia) a výpočty predstavujú *flow* týchto dát. Na začiatok zadefinujeme jednoduchú operáciu sčítania pomocou TensorFlow:\n",
    "\n",
    "![](figures/lab1-addition.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the nodes in the graph, and initialize values\n",
    "a = tf.constant(13, name=\"a\")\n",
    "b = tf.constant(37, name=\"b\")\n",
    "\n",
    "# add together the two values\n",
    "c = tf.add(a, b, name=\"c\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na základe predošlého príkladu vytvorte trošku viac zložitý graf:\n",
    "\n",
    "![](figures/lab1-complicated-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the nodes in the graph, and initialize values\n",
    "a = tf.constant(2.5, name=\"a\")\n",
    "b = tf.constant(6.5, name=\"b\")\n",
    "\n",
    "c = tf.add(a, b, name=\"c\")\n",
    "d = tf.subtract(b, 1, name=\"d\")\n",
    "e = tf.multiply(c, d, name=\"e\")\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptrón\n",
    "\n",
    "Perceptrón je neurón navrhnutý Frankom Rosenblattom, ktorý predstavuje základný výpočtový prvok neurónových sietí. Štruktúru resp. topológiu perceptrónu vidíte na obrázku.\n",
    "\n",
    "![Štruktúra perceptrónu](figures/lab1-perceptron.png)\n",
    "\n",
    "Výpočet v perceptróne sa pozostáva z váženej sumy, pripočítaní biasu a aplikácie aktivačnej funkcie. Pri vytvorení robustných neurónových sietí hlbokého učenia budeme používať Keras API, ale v tomto kroku vytvoríme jednoduchý perceptrón pomocou základnych metód TensorFlow. Aby sme si vedeli skontrolovať, či naše riešenie funguje správne, zadefinujeme nielen vstupy, ale aj váhy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple perceptron with two input nodes\n",
    "def my_perceptron(x):\n",
    "    # define some arbitrary weights for the two input values\n",
    "    W = tf.constant([[3, -2]], shape=(1, 2), dtype=tf.float32)\n",
    "\n",
    "    # define the bias of the perceptron\n",
    "    b = 1\n",
    "    \n",
    "    # compute weighted sum (hint: check out tf.matmul)\n",
    "    z = tf.matmul(x, W, transpose_b=True) + b\n",
    "\n",
    "    # apply the sigmoid activation function (hint: use tf.sigmoid)\n",
    "    output = tf.sigmoid(z)\n",
    "\n",
    "    return output\n",
    "\n",
    "sample_input = tf.constant([[-1, 2]], shape=(1, 2), dtype=tf.float32)\n",
    "\n",
    "# if you've done everything correctly, this should give you a tensor with value 0.002\n",
    "result = my_perceptron(sample_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neurónové siete\n",
    "\n",
    "Ak chceme naše siete natrénovať, konštantné váhy nám nepomôžu a práve preto si teraz opravím predchádzajúcí kód tak, aby sme výsledný model vedeli natrénovať. Zároveň, náš model rozšírime o niekoľko neurónov, tak aby sme dostali *fully connected* (*dense*) vrstvu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x: input values\n",
    "# n_in: number of input nodes\n",
    "# n_out: number of output nodes\n",
    "def my_dense_layer(x, n_in, n_out):\n",
    "    # define variable weights as a matrix and biases\n",
    "    # initialize weights for one\n",
    "    # initialize biases for zero\n",
    "    W = tf.Variable(tf.ones((n_in, n_out)))\n",
    "    b = tf.Variable(tf.zeros((1, n_out)))\n",
    "    \n",
    "    # compute weighted sum (hint: check out tf.matmul)\n",
    "    z = tf.matmul(x, W) + b\n",
    "\n",
    "    # apply the sigmoid activation function (hint: use tf.sigmoid)\n",
    "    output = tf.sigmoid(z)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako aj pred tým, naše riešenie vieme otestovať zadaním ľubovoľných hodnôt (s dodržaním počtu vstupných a výstupných neurónov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_input = tf.constant([[1, 2.]], shape=(1, 2))\n",
    "print(my_dense_layer(sample_input, n_in=2, n_out=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Síce definícia jednej vrstvy nie je až také problemtické, pri vytvorení hlbokých sietí by sme sa veľmi rýchlo narazili na problém. Práve preto sa pozrieme na to, ako by sme vedeli vytvoriť rovnaký model pomocou Keras API.\n",
    "\n",
    "Keras nám ponúka niekoľko pripravených štandardných riešení, z ktorých my teraz použijeme [Dense](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Sequential) vrstvu a [Sequential](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Sequential) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# define the number of input and output nodes\n",
    "n_input_nodes = 2\n",
    "n_output_nodes = 3\n",
    "\n",
    "# first define the model\n",
    "model = Sequential()\n",
    "\n",
    "# define a dense layer based on weights and biases\n",
    "dense_layer = Dense(n_output_nodes, input_shape=(n_input_nodes, ), activation='sigmoid')\n",
    "\n",
    "model.add(dense_layer)\n",
    "\n",
    "x_input = tf.constant([[1, 2.]], shape=(1, 2))\n",
    "\n",
    "# feed the input into the model and predict the output\n",
    "print(model.predict(x_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Trénovanie neurónovej siete\n",
    "\n",
    "Trénovanie neurónovej siete sa najčastejšie robí pomocou gradient descent, proces, ktorý úspešne hľadá minimum v *n+1* dimenzionálnom prostredí, kde *n* je počet váh a dimenzia +1 vyjadruje chybu pri danej konfigurácii váh. Vďaka Eager vykonávania vieme tento proces vizualizovať na príklade derivácie jednoduchej funkcie *y = (x - 1)<sup>2</sup>*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = tf.Variable([tf.random.normal([1])])\n",
    "print(\"Initializing x={}\".format(x.numpy()))\n",
    "learning_rate = 1e-2\n",
    "history = []\n",
    "\n",
    "for i in range(500):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = (x - 1)**2 # record the forward pass on the tape\n",
    "\n",
    "        grad = tape.gradient(y, x) # compute the gradient of y with respect to x\n",
    "        new_x = x - learning_rate*grad # sgd update\n",
    "        x.assign(new_x) # update the value of x\n",
    "        history.append(x.numpy()[0])\n",
    "\n",
    "plt.plot(history)\n",
    "plt.plot([0, 500],[1,1])\n",
    "plt.legend(('Predicted', 'True'))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('x value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
